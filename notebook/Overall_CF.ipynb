{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    '''\n",
    "    Compute the Jaccard similarity.\n",
    "    :param s1: set 1                (set)\n",
    "    :param s2: set 2                (set)\n",
    "    :return: Jaccard coefficient    (float)\n",
    "    '''\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "def Cosine(x, y):\n",
    "    '''\n",
    "    Compute cosine similarity.\n",
    "    :param x: vector 1              (set)\n",
    "    :param y: vector 2              (set)\n",
    "    :return: Cosine coefficient     (float)\n",
    "    '''\n",
    "    x[x == 1] = -1\n",
    "    y[y == 1] = -1\n",
    "    x[x == 2] = -1\n",
    "    y[y == 2] = -1\n",
    "    x[x >= 3] = 1\n",
    "    y[y >= 3] = 1   \n",
    "    return (x @ y.T) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "\n",
    "def Pearson(x, y):\n",
    "    '''\n",
    "    Compute Pearson correlation coefficient.\n",
    "    :param x: vector 1              (set)\n",
    "    :param y: vector 2              (set)\n",
    "    :return: Pearson coeff.         (float)\n",
    "    '''\n",
    "    x_valid = x[x != 0]\n",
    "    y_valid = y[y != 0]\n",
    "    mean_x = np.mean(x_valid)\n",
    "    mean_y = np.mean(y_valid)\n",
    "    x[x != 0] -= mean_x\n",
    "    y[y != 0] -= mean_y\n",
    "    if (np.linalg.norm(x) * np.linalg.norm(y)) == 0: return 0\n",
    "    else: return (x @ y.T) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    '''\n",
    "    Load the data.\n",
    "    :param file: directory of a csv file.\n",
    "    :return: 80% train_data + 20% test_data\n",
    "        \n",
    "    '''\n",
    "    assert os.path.splitext(file)[-1] == \".csv\"\n",
    "\n",
    "    data = pd.read_csv(file)\n",
    "    data.pop('Unnamed: 0')\n",
    "\n",
    "    train_data, test_data = train_test_split(data, test_size = 0.2, random_state=1)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(prod, user,\n",
    "                  globalMean, meanRatings,\n",
    "                  usersPerItem, itemsPerUser,\n",
    "                  reviewsPerItem, reviewsPerUser,\n",
    "                  feature_matrix, feature_matrix_T,\n",
    "                  base='item', simi='Cosine'):\n",
    "    '''\n",
    "    Predict the rating of a user to a product.\n",
    "    :param prod:                 product id (str)\n",
    "    :param user:                 user id (str)\n",
    "    :param globalMean:           global mean rating in the training set (float)\n",
    "    :param meanRatings:          mean ratings for users (dict) \n",
    "    :param usersPerItem:         sets of all users of an item (dict)\n",
    "    :param itemsPerUser:         sets of all items of a user (dict)\n",
    "    :param reviewsPerItem:       reviews of each item (list)\n",
    "    :param reviewsPerUser:       reviews of each user (list)\n",
    "    :param feature_matrix:       rows == userID, columns == productID\n",
    "    :param feature_matrix_T:     rows == productID, columns == userID\n",
    "    :param base:                 type of collaborative filter (\"item\" or \"user\")\n",
    "    :param simi:                 the similarity rule applied (\"Jaccard\" or \"Cosine\" or \"Pearson\")\n",
    "    '''\n",
    "\n",
    "    assert base == 'item' or base == 'user'\n",
    "    assert simi == 'Jaccard' or simi == 'Cosine' or simi == 'Pearson'\n",
    "    \n",
    "    scores = []\n",
    "    similarities = []\n",
    "\n",
    "    if base == 'item':\n",
    "        for cur_prod, cur_score in reviewsPerUser[user]:\n",
    "            if cur_prod == prod: continue\n",
    "            scores.append(cur_score)\n",
    "            \n",
    "            try:\n",
    "                if simi == 'Jaccard':\n",
    "                    similarities.append(Jaccard(usersPerItem[prod], usersPerItem[cur_prod]))\n",
    "                elif simi == 'Cosine':\n",
    "                    similarities.append(Cosine(np.array(feature_matrix[prod]), np.array(feature_matrix[cur_prod])))\n",
    "                else:\n",
    "                    similarities.append(Pearson(np.array(feature_matrix[prod]), np.array(feature_matrix[cur_prod])))\n",
    "            except:\n",
    "                similarities.append(0)\n",
    "\n",
    "        if sum(similarities) != 0:\n",
    "            weightedScores = [(x*y) for x,y in zip(scores, similarities)]\n",
    "            return sum(weightedScores) / np.sum(np.abs(similarities))\n",
    "\n",
    "        else: return globalMean\n",
    "\n",
    "\n",
    "    else:\n",
    "        users = []\n",
    "        for cur_user, cur_score in reviewsPerItem[prod]:\n",
    "            if cur_user == user: continue\n",
    "            scores.append(cur_score)\n",
    "            \n",
    "            try:\n",
    "                if simi == 'Jaccard':\n",
    "                    similarities.append(Jaccard(itemsPerUser[user], itemsPerUser[cur_user]))\n",
    "                elif simi == 'Cosine':\n",
    "                    similarities.append(Cosine(np.array(feature_matrix_T[user]), np.array(feature_matrix_T[cur_user])))\n",
    "                else:\n",
    "                    similarities.append(Pearson(np.array(feature_matrix_T[user]), np.array(feature_matrix_T[cur_user])))\n",
    "            except:\n",
    "                similarities.append(0)\n",
    "\n",
    "            users.append(cur_user)\n",
    "\n",
    "        if sum(similarities) != 0:\n",
    "            if user not in meanRatings:\n",
    "                weightedScores = [(x*y) for x,y in zip(scores, similarities)]\n",
    "                rating_pred = sum(weightedScores) / np.sum(np.abs(similarities))\n",
    "            else:\n",
    "                weightedScores = [((x-meanRatings[u])*y) if u in meanRatings else 0 for x,y,u in zip(scores, similarities, users)]\n",
    "                rating_pred = meanRatings[user] + sum(weightedScores) / np.sum(np.abs(similarities))\n",
    "            return rating_pred\n",
    "        \n",
    "        else: return globalMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'clean2.csv'\n",
    "train_data, test_data = load_data(data_dir)\n",
    "labels = list(test_data['Score'])\n",
    "\n",
    "feature_matrix = pd.pivot_table(train_data, values='Score', index=['UserId'], columns=['ProductId'])\n",
    "feature_matrix.fillna(0, inplace=True)\n",
    "feature_matrix_T = pd.DataFrame.transpose(feature_matrix)\n",
    "\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "for row in train_data.itertuples():\n",
    "    prod, user, score = row[1], row[2], row[3]\n",
    "    usersPerItem[prod].add(user)\n",
    "    itemsPerUser[user].add(prod)\n",
    "    reviewsPerUser[user].append((prod, score))\n",
    "    reviewsPerItem[prod].append((user, score))\n",
    "\n",
    "globalMean = sum(train_data['Score'])/len(train_data)\n",
    "meanRatings = {}\n",
    "for i, user in enumerate(feature_matrix.columns):\n",
    "    ratings = feature_matrix[user]\n",
    "    ratingsValid = ratings[ratings != 0]\n",
    "    meanRatings[user] = np.mean(ratingsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13603/13603 [01:07<00:00, 201.79it/s]\n"
     ]
    }
   ],
   "source": [
    "alwaysPredictMean = [globalMean for _ in range(len(test_data))]\n",
    "cfPredictions = []\n",
    "for j in tqdm(range(len(test_data.index))):\n",
    "    i = test_data.index[j]\n",
    "    cfPredictions.append(predictRating(test_data['ProductId'][i], test_data['UserId'][i], \n",
    "                                       globalMean, meanRatings, \n",
    "                                       usersPerItem, itemsPerUser, \n",
    "                                       reviewsPerItem, reviewsPerUser, \n",
    "                                       feature_matrix, feature_matrix_T, \n",
    "                                       base='item', simi='Cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For baseline = 1.3688432313621304\n",
      "The MSE of rating estimation is 0.9545808842338184\n"
     ]
    }
   ],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "cfPredictions = np.array(cfPredictions)\n",
    "cfPredictions[cfPredictions < 1] = 1\n",
    "cfPredictions[cfPredictions > 5] = 5\n",
    "err_baseline = MSE(alwaysPredictMean, labels)\n",
    "err_CF = MSE(cfPredictions, labels)\n",
    "print('For baseline =', err_baseline)\n",
    "print('The MSE of rating estimation is', err_CF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
